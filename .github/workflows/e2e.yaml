name: e2e
on:
  workflow_dispatch:
  pull_request:
  push:
    branches:
      - main
      - release-v0.14

permissions:
  contents: read # for actions/checkout to fetch code

jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Setup YQ
        uses: frenck/action-setup-yq@v1
        with:
          version: 4.14.2
      - name: Setup QEMU
        uses: docker/setup-qemu-action@v1
        with:
          platforms: all
      - name: Setup Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v1
        with:
          buildkitd-flags: "--debug"
      - name: Setup Go
        uses: actions/setup-go@v2
        with:
          go-version: 1.19.x
      - name: Restore Go cache
        uses: actions/cache@v1
        with:
          path: ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-
      - name: Cache Docker layers
        uses: actions/cache@v2
        id: cache
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-ghcache-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-ghcache-
      - name: Setup Kubernetes
        uses: engineerd/setup-kind@v0.5.0
        with:
          version: v0.11.1
          image: kindest/node:v1.21.1@sha256:fae9a58f17f18f06aeac9772ca8b5ac680ebbed985e266f711d936e91d113bad
      - name: Setup Kustomize
        uses: fluxcd/pkg/actions/kustomize@main
      - name: Setup Kubectl
        uses: fluxcd/pkg/actions/kubectl@main
      - name: Check if working tree is dirty
        run: |
          if [[ $(git diff --stat) != '' ]]; then
            git --no-pager diff
            echo 'run make test and commit changes'
            exit 1
          fi
      - name: Build the tf-controller container image
        run: |
          VERSION="e2e-${GITHUB_SHA::8}"

          make docker-buildx MANAGER_IMG=test/tf-controller RUNNER_IMG=test/tf-runner TAG=$VERSION \
            BUILD_ARGS="--cache-from=type=local,src=/tmp/.buildx-cache \
              --cache-to=type=local,dest=/tmp/.buildx-cache-new,mode=max \
              --load"
      - # Temp fix
        # https://github.com/docker/build-push-action/issues/252
        # https://github.com/moby/buildkit/issues/1896
        name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache
      - name: Load test images into KIND
        run: |
          VERSION="e2e-${GITHUB_SHA::8}"

          kind load docker-image test/tf-controller:$VERSION
          kind load docker-image test/tf-runner:$VERSION
      - name: Install CRDs
        run: make install
      - name: Deploy controllers
        run: |
          VERSION="e2e-${GITHUB_SHA::8}"

          # Patch env RUNNER_POD_IMAGE to be test/tf-runner:$VERSION
          yq -i e ".spec.template.spec.containers[0].env[1].value=\"test/tf-runner:$VERSION\"" config/manager/manager.yaml

          # Dev deploy - do it twice to make sure the CRDs get in first
          make dev-deploy MANAGER_IMG=test/tf-controller RUNNER_IMG=test/tf-runner TAG=$VERSION || true
          make dev-deploy MANAGER_IMG=test/tf-controller RUNNER_IMG=test/tf-runner TAG=$VERSION

          # Increase the concurrency of the controller to speed up tests
          kubectl patch deployment \
            tf-controller \
            --namespace tf-system \
            --type='json' \
            -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/args", "value": [
            "--watch-all-namespaces",
            "--log-level=info",
            "--log-encoding=json",
            "--enable-leader-election",
            "--concurrent=10",
          ]}]'

          kubectl -n tf-system rollout status deploy/source-controller --timeout=1m
          kubectl -n tf-system rollout status deploy/tf-controller --timeout=1m
      - name: Get terraform version
        run: |
          # Terraform binary will be moved from the TF-controller image to TF-runner, so we check TF's version there
          VERSION="e2e-${GITHUB_SHA::8}"
          docker run --rm --entrypoint=/usr/local/bin/terraform test/tf-runner:$VERSION version
      - name: Add git repository source
        run: |
          kubectl -n tf-system apply -f ./config/testdata/source
          kubectl -n tf-system wait gitrepository/helloworld --for=condition=ready --timeout=4m
          kubectl -n tf-system wait ocirepository/helloworld-oci --for=condition=ready --timeout=4m
      - name: Run approvePlan tests
        run: |
          kubectl -n tf-system apply -f ./config/testdata/approve-plan
          kubectl -n tf-system wait terraform/helloworld-auto-approve --for=condition=ready --timeout=4m
          kubectl -n tf-system wait terraform/helloworld-oci-auto-approve --for=condition=ready --timeout=4m
          kubectl -n tf-system wait terraform/helloworld-manual-approve --for=condition=plan=true --timeout=4m

          # delete after tests
          kubectl -n tf-system delete -f ./config/testdata/approve-plan
      - name: Run plan with pod cleanup tests
        run: |
          kubectl -n tf-system apply -f ./config/testdata/always-clean-pod
          kubectl -n tf-system wait terraform/helloworld-always-clean-pod-manual-approve --for=condition=plan=true --timeout=4m

          # negate pod not found to be true
          ! kubectl -n tf-system get terraform/helloworld-always-clean-pod-manual-approve-tf-runner

          # delete after tests
          kubectl -n tf-system delete -f ./config/testdata/always-clean-pod
      - name: Run drift detection tests
        run: |
          kubectl -n tf-system apply -f ./config/testdata/drift-detection
          kubectl -n tf-system wait terraform/helloworld-drift-detection --for=condition=ready=unknown --timeout=4m
          kubectl -n tf-system wait terraform/helloworld-drift-detection-disable --for=condition=ready --timeout=4m

          # delete after tests
          kubectl -n tf-system delete -f ./config/testdata/drift-detection
      - name: Run healthchecks tests
        run: |
          kubectl -n tf-system apply -f ./config/testdata/healthchecks
          kubectl -n tf-system wait terraform/helloworld-healthchecks --for=condition=ready --timeout=4m

          # delete after tests
          kubectl -n tf-system delete -f ./config/testdata/healthchecks
      - name: Run vars tests
        run: |
          kubectl -n tf-system apply -f ./config/testdata/vars
          kubectl -n tf-system wait terraform/helloworld-vars --for=condition=ready --timeout=4m

          # delete after tests
          kubectl -n tf-system delete -f ./config/testdata/vars
      - name: Run multi-tenancy test
        run: |
          kubectl -n tf-system scale --replicas=3 deploy/tf-controller
          kustomize build ./config/testdata/multi-tenancy/tenant01 | kubectl apply -f -
          kustomize build ./config/testdata/multi-tenancy/tenant02 | kubectl apply -f -
          kubectl -n tf-tenant01-dev wait terraform/helloworld-tenant01-dev --for=condition=ready --timeout=4m
          kubectl -n tf-tenant01-prd wait terraform/helloworld-tenant01-prd --for=condition=ready --timeout=4m
          kubectl -n tf-tenant02-dev wait terraform/helloworld-tenant02-dev --for=condition=ready --timeout=4m
          kubectl -n tf-tenant02-prd wait terraform/helloworld-tenant02-prd --for=condition=ready --timeout=4m

          # delete after tests
          kubectl -n tf-tenant01-dev delete terraform --all
          kubectl -n tf-tenant01-prd delete terraform --all
          kubectl -n tf-tenant02-dev delete terraform --all
          kubectl -n tf-tenant02-prd delete terraform --all

          kubectl -n tf-tenant01-dev delete gitrepository --all
          kubectl -n tf-tenant01-prd delete gitrepository --all
          kubectl -n tf-tenant02-dev delete gitrepository --all
          kubectl -n tf-tenant02-prd delete gitrepository --all

          kubectl delete ns tf-tenant01-dev 
          kubectl delete ns tf-tenant01-prd 
          kubectl delete ns tf-tenant02-dev 
          kubectl delete ns tf-tenant02-prd 

      - name: Set up chaos testing environment
        run: |
          # TODO we'll test a race condition with replica=3 later
          kubectl -n tf-system scale --replicas=1 deploy/tf-controller

          kubectl -n chaos-testing apply -f ./config/testdata/chaos
          kubectl -n chaos-testing apply -f ./config/testdata/source
          sleep 10
      - name: Randomly delete runner pods
        run: |
          # use chaos level 3 at the moment, as we don't have much CPU resources
          seq 5 | shuf | head -3 | xargs -I{} bash -c "kubectl -n chaos-testing delete pod helloworld-chaos0{}-tf-runner || true"
          sleep 10
      - name: Verify chaos testing result
        run: |
          kubectl -n chaos-testing get pods

          kubectl -n chaos-testing wait terraform/helloworld-chaos01 --for=condition=ready --timeout=30m
          kubectl -n chaos-testing wait terraform/helloworld-chaos02 --for=condition=ready --timeout=30m
          kubectl -n chaos-testing wait terraform/helloworld-chaos03 --for=condition=ready --timeout=30m
          kubectl -n chaos-testing wait terraform/helloworld-chaos04 --for=condition=ready --timeout=30m
          kubectl -n chaos-testing wait terraform/helloworld-chaos05 --for=condition=ready --timeout=30m
      - name: Logs
        run: |
          kubectl -n tf-system logs deploy/source-controller
          kubectl -n tf-system logs deploy/tf-controller
      - name: Debug failure
        if: failure()
        run: |
          which kubectl
          kubectl version
          kustomize version
          kubectl -n tf-system logs deploy/source-controller
          kubectl -n tf-system logs deploy/tf-controller

          ns=(tf-system tf-tenant01-dev tf-tenant01-prd tf-tenant02-dev tf-tenant02-prd chaos-testing)
          for n in "${ns[@]}"
          do
            kubectl -n $n get gitrepositories -oyaml          
            kubectl -n $n get terraforms -oyaml
            kubectl -n $n get all
          done
